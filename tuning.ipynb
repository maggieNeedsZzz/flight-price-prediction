{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Price Prediction\n",
    "#### Tuning with CV and logging with MLFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class Dropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.feature_names)\n",
    "\n",
    "class Normalizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.numericalFeatures = X.select_dtypes(exclude='object').columns\n",
    "        self.otherFeatures = X.columns.difference(self.numericalFeatures)\n",
    "        self.scaler.fit(X[self.numericalFeatures])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df_normalized = pd.DataFrame(self.scaler.transform(X[self.numericalFeatures]), columns=self.numericalFeatures)\n",
    "        return pd.concat([df_normalized, X[self.otherFeatures]], axis=1)\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.ohEncoder = OneHotEncoder()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.categoricalFeatures = X.select_dtypes(include='object').columns\n",
    "        self.otherFeatures = X.columns.difference(self.categoricalFeatures)\n",
    "        self.ohEncoder.fit(X[self.categoricalFeatures])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df_encoded = pd.DataFrame(self.ohEncoder.transform(X[self.categoricalFeatures]).toarray(), columns=self.ohEncoder.get_feature_names_out())\n",
    "        return pd.concat([df_encoded, X[self.otherFeatures]], axis=1)\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('flightDrop', Dropper(['flight'])),\n",
    "    # ('targetDrop', Dropper(['target'])),\n",
    "    ('encoder', CategoricalEncoder()),\n",
    "    ('scaler', Normalizer())\n",
    "])\n",
    "\n",
    "\n",
    "X = pd.read_csv(os.path.join('../archive', 'Clean_Dataset.csv'), index_col=0)\n",
    "X = pipe.fit_transform(X)\n",
    "y = X['price'].to_numpy().reshape(-1, 1)\n",
    "X.drop(columns=['price'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "\n",
    "    ( \n",
    "        \"Decision Tree\",\n",
    "        DecisionTreeRegressor(),\n",
    "        {\n",
    "            'max_depth': [3, 4, 5, 8, 12, 25, 40],\n",
    "            'min_samples_split': [2, 4, 6, 8],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\",\n",
    "        RandomForestRegressor(),\n",
    "        {\n",
    "            'n_estimators': [100, 200, 300, 500],\n",
    "            'max_depth': [5, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'bootstrap': [True, False]\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        \"Gradient Boosting\",\n",
    "        GradientBoostingRegressor(),\n",
    "        {\n",
    "            'n_estimators': [100, 200, 300, 500],\n",
    "            'learning_rate': [0.1, 0.05, 0.01],\n",
    "            'max_depth': [3, 4, 5, 6],\n",
    "            'min_samples_split': [2, 4, 6],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "            #\"loss\": \"squared_error\",\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        \"XBGradient Boost\",\n",
    "        XGBRegressor(),\n",
    "        {\n",
    "            'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'learning_rate': [0.1, 0.05, 0.01, 0.001],\n",
    "\n",
    "            # Overfitting \n",
    "            'min_child_weight' : [3, 10, 50, 100, 200],\n",
    "            'max_depth': [6, 8, 16],\n",
    "            'gamma': [0, 0.1, 0.5],\n",
    "\n",
    "            'subsample': [0.5, 0.8, 1],\n",
    "            'colsample_bytree': [0.5, 0.8, 1],\n",
    "            # 'eta' : [0.01, 0.05, 0.1 , 0.2]\n",
    "            # 'num_round' : [ ] \n",
    "\n",
    "            # 'reg_alpha': [0, 0.1, 0.5], \n",
    "            # 'reg_lambda': [0, 0.1, 0.5]\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        \"Neural Network (MLP Regressor)\",\n",
    "        MLPRegressor(max_iter=1000),\n",
    "        {\n",
    "            'hidden_layer_sizes': [(50,50), (100,), (100, 50)],\n",
    "            'activation': ['relu', 'tanh'],\n",
    "            'solver': ['adam', 'sgd'],\n",
    "            'learning_rate': ['constant', 'adaptive']\n",
    "        }\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RMSE because it penalizes large errors and is  easy to interpret (same scale as prices).\n",
    "\n",
    "In pricing predictions, RMSE is commonly used as it directly measures prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(model, params, X, y, tuning_type='grid', cv=5, n_iter=10, scoring='neg_root_mean_squared_error', random_state=42):\n",
    "    search = None\n",
    "    \n",
    "    if tuning_type == 'grid':\n",
    "        search = GridSearchCV(model, param_grid=params, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    elif tuning_type == 'random':\n",
    "        search = RandomizedSearchCV(model, param_distributions=params, cv=cv, n_iter=n_iter, \n",
    "                                    scoring=scoring, random_state=random_state, n_jobs=-1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid tuning_type. Choose either 'grid' or 'random'.\")\n",
    "\n",
    "    search.fit(X, y) \n",
    "    \n",
    "    best_params = search.best_params_\n",
    "    best_score = search.best_score_\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    print(f\"Scoring is {scoring}\")\n",
    "    print(\"Best Cross-Validation Score:\", best_score)\n",
    "    # print(\"Best Parameters:\", best_params)\n",
    "    \n",
    "    return best_params, best_score, best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best parameters using random or grid search w/ CV.\n",
    "\n",
    "Then saves model, parameters, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring is neg_root_mean_squared_error\n",
      "Best Cross-Validation Score: -0.04178971600569685\n",
      "------------------------------\n",
      "Model: Decision Tree\n",
      "  Best CV Score: -0.0418\n",
      "  RMSE: 0.0476\n",
      "  MAE: 0.0287\n",
      "  R²: 0.9348\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marga\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring is neg_root_mean_squared_error\n",
      "Best Cross-Validation Score: -0.04333864404919406\n",
      "------------------------------\n",
      "Model: Random Forest\n",
      "  Best CV Score: -0.0433\n",
      "  RMSE: 0.0354\n",
      "  MAE: 0.0196\n",
      "  R²: 0.9638\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marga\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring is neg_root_mean_squared_error\n",
      "Best Cross-Validation Score: -0.03960334651663975\n",
      "------------------------------\n",
      "Model: Gradient Boosting\n",
      "  Best CV Score: -0.0396\n",
      "  RMSE: 0.0401\n",
      "  MAE: 0.0236\n",
      "  R²: 0.9537\n",
      "------------------------------\n",
      "\n",
      "Scoring is neg_root_mean_squared_error\n",
      "Best Cross-Validation Score: -0.040003799863844024\n",
      "------------------------------\n",
      "Model: XBGradient Boost\n",
      "  Best CV Score: -0.0400\n",
      "  RMSE: 0.0375\n",
      "  MAE: 0.0223\n",
      "  R²: 0.9595\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marga\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1617: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring is neg_root_mean_squared_error\n",
      "Best Cross-Validation Score: -0.047364349192800304\n",
      "------------------------------\n",
      "Model: Neural Network (MLP Regressor)\n",
      "  Best CV Score: -0.0474\n",
      "  RMSE: 0.0334\n",
      "  MAE: 0.0198\n",
      "  R²: 0.9679\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_logs = []\n",
    "\n",
    "for model_name, model, params in models:\n",
    "    \n",
    "    best_params, best_score, best_model = hyperparameter_tuning(model, params, X, y, tuning_type='random')\n",
    "\n",
    "    # best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"MAE\" : mae,\n",
    "        \"RMSE\" : rmse,\n",
    "        \"r2\" : r2,\n",
    "        \"best CV RMSE\" : best_score\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    print('-' * 30)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"  Best CV Score: {best_score:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R²: {r2:.4f}\")\n",
    "    print('-' * 30)\n",
    "    print()\n",
    "\n",
    "    model_logs.append({\n",
    "        \"model_name\": model_name,\n",
    "        \"model\": best_model,\n",
    "        \"params\": best_params,\n",
    "        # \"score\": best_score,\n",
    "        \"metrics\": metrics,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 21:46:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Decision Tree at: http://localhost:5000/#/experiments/675764874958078904/runs/6abb9a20680549e69c726913e3f806c1\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/675764874958078904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 21:46:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Random Forest at: http://localhost:5000/#/experiments/675764874958078904/runs/8801d978318e4cfaa32c0421f2801910\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/675764874958078904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 21:46:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Gradient Boosting at: http://localhost:5000/#/experiments/675764874958078904/runs/762de682d3e14f44aeb5775a65939e0f\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/675764874958078904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 21:47:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XBGradient Boost at: http://localhost:5000/#/experiments/675764874958078904/runs/d21596d3207f4d41b1c1ee42aa4c8259\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/675764874958078904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/16 21:47:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Neural Network (MLP Regressor) at: http://localhost:5000/#/experiments/675764874958078904/runs/7e39ef9589e4420f994aab2477090888\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/675764874958078904\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "\n",
    "# run_name = \"tuning\"\n",
    "# artifact_path = \"artifact\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Model Tuning\")\n",
    "\n",
    "for i, element in enumerate(model_logs):\n",
    "    model_name = element[\"model_name\"]\n",
    "    model = element[\"model\"]\n",
    "    params = element[\"params\"]\n",
    "    metrics = element[\"metrics\"]\n",
    "\n",
    "    # model_name = element[0]\n",
    "    # model = element[1]\n",
    "    # params = element[2]\n",
    "    # metrics = model_logs[i]\n",
    "    \n",
    "    # with mlflow.start_run(run_name=run_name) as run:\n",
    "    with mlflow.start_run():\n",
    "        #   model.get_depth()  model.get_n_leaves())\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics(metrics)  \n",
    "        # mlflow.set_tag(\"Training Info\", model_name)\n",
    "        mlflow.set_tag(\"mlflow.runName\", model_name)\n",
    "\n",
    "        # signature = infer_signature(X_train, model.predict(X_train))\n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, model_name)\n",
    "            # mlflow.xgboost.log_model(\n",
    "            #     sk_model=model, input_example=X_test, artifact_path=artifact_path\n",
    "            # )\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, model_name)  \n",
    "            # mlflow.sklearn.log_model(\n",
    "            #     sk_model=model, input_example=X_test, artifact_path=artifact_path\n",
    "            # )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'NN' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Not a proper runs:/ URI: runs:7e39ef9589e4420f994aab2477090888/NN. Runs URIs must be of the form 'runs:/<run_id>/run-relative/path/to/artifact'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNN\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marga\\.conda\\envs\\ml\\lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:77\u001b[0m, in \u001b[0;36mregister_model\u001b[1;34m(model_uri, name, await_registration_for, tags)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregister_model\u001b[39m(\n\u001b[0;32m     18\u001b[0m     model_uri,\n\u001b[0;32m     19\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     tags: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     23\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelVersion:\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new model version in model registry for the model files specified by ``model_uri``.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    Note that this method assumes the model registry backend URI is the same as that of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m        Version: 1\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_register_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marga\\.conda\\envs\\ml\\lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:108\u001b[0m, in \u001b[0;36m_register_model\u001b[1;34m(model_uri, name, await_registration_for, tags, local_model_path)\u001b[0m\n\u001b[0;32m    106\u001b[0m source \u001b[38;5;241m=\u001b[39m model_uri\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mis_runs_uri(model_uri):\n\u001b[1;32m--> 108\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[43mRunsArtifactRepository\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_underlying_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     (run_id, _) \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mparse_runs_uri(model_uri)\n\u001b[0;32m    111\u001b[0m create_version_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_create_model_version(\n\u001b[0;32m    112\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    113\u001b[0m     source\u001b[38;5;241m=\u001b[39msource,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m     local_model_path\u001b[38;5;241m=\u001b[39mlocal_model_path,\n\u001b[0;32m    118\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\marga\\.conda\\envs\\ml\\lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:37\u001b[0m, in \u001b[0;36mRunsArtifactRepository.get_underlying_uri\u001b[1;34m(runs_uri)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_underlying_uri\u001b[39m(runs_uri):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifact_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_artifact_uri\n\u001b[1;32m---> 37\u001b[0m     (run_id, artifact_path) \u001b[38;5;241m=\u001b[39m \u001b[43mRunsArtifactRepository\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_runs_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruns_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     tracking_uri \u001b[38;5;241m=\u001b[39m get_databricks_profile_uri_from_artifact_uri(runs_uri)\n\u001b[0;32m     39\u001b[0m     uri \u001b[38;5;241m=\u001b[39m get_artifact_uri(run_id, artifact_path, tracking_uri)\n",
      "File \u001b[1;32mc:\\Users\\marga\\.conda\\envs\\ml\\lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:54\u001b[0m, in \u001b[0;36mRunsArtifactRepository.parse_runs_uri\u001b[1;34m(run_uri)\u001b[0m\n\u001b[0;32m     52\u001b[0m path \u001b[38;5;241m=\u001b[39m parsed\u001b[38;5;241m.\u001b[39mpath\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(path) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot a proper runs:/ URI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRuns URIs must be of the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns:/<run_id>/run-relative/path/to/artifact\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m     )\n\u001b[0;32m     58\u001b[0m path \u001b[38;5;241m=\u001b[39m path[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     60\u001b[0m path_parts \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mMlflowException\u001b[0m: Not a proper runs:/ URI: runs:7e39ef9589e4420f994aab2477090888/NN. Runs URIs must be of the form 'runs:/<run_id>/run-relative/path/to/artifact'"
     ]
    }
   ],
   "source": [
    "\n",
    "run_id = \"7e39ef9589e4420f994aab2477090888\"\n",
    "model_name = \"NN\"\n",
    "model_uri = f\"runs:{run_id}/{model_name}\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri, model_name\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
